// #include <iostream>
// #include <fstream>
// #include <sstream>
// #include <string>
// #include <cstring>
// #include <vector>
// #include <event.h>
// #include <hdf5.h>
// #include <chrono>
// #include <chunkattr.h>

// #define DATASET_RANK 1
// #define ATTR_CHUNKMETADATA "ChunkMetadata"
// #define ATTR_MIN "Min"
// #define ATTR_MAX "Max"
// #define CHUNK_META_ATTR_RANK 1
// #define MIN_ATTR_RANK 1
// #define MAX_ATTR_RANK 1
// #define DEBUG 0
// #define CHUNK_SIZE 100

// // Write data to H5 dataset. returns status as 0 if write is successful else returns 1
// int writeToDataset(std::vector<Event> storyChunk, const char* FILE_NAME, const char* DATASET_NAME, const char* H5FILE_NAME, bool operationType) {

//     // Disable automatic printing of HDF5 error stack
//     if(!DEBUG){
//         H5Eset_auto(H5E_DEFAULT, NULL, NULL);
//     }

//     hid_t   file, dataset, space, cspace, dcpl_id, memorySpace, eventType, at_tid, attr, attr1, min_attr, max_attr;
//     hid_t   plist_id, dataspace_id, attribute_id, attribute_type, dataspace_a_id;
//     herr_t  status, ret;
//     Event* eventBuffer;
//     ChunkAttr* attrBuffer;
//     ChunkAttr* attribute_data;
//     hsize_t chunk_dims[1] = {CHUNK_SIZE};

//     /*
//      * Number of events
//      */
//     const hsize_t numEvents = storyChunk.size() - 1;

//     /*
//      * Allocate memory for events buffer
//      */
//     eventBuffer = (Event*) malloc(numEvents * sizeof(Event));
//     if(eventBuffer == NULL){
//         std::cout<<"Error creating events buffer"<<std::endl;
//         return -1;
//     }
    
//     /*
//      * Allocate memory for attribute buffer
//      */
//     attrBuffer = (ChunkAttr*) malloc(((numEvents / CHUNK_SIZE) + 1) * sizeof(ChunkAttr));
//     std::cout<<"ChunkAttr"<<((numEvents / CHUNK_SIZE) + 1)<<std::endl;
//     if(attrBuffer == NULL){
//         std::cout<<"Error creating attribute buffer"<<std::endl;
//         free(eventBuffer);
//         return -1;
//     }

//     /*
//      * Read data from storyChunk into buffer
//      */
//     for(int iter = 0 ; iter < numEvents ; iter++) {
//        eventBuffer[iter].timeStamp = storyChunk[iter].timeStamp;
//        strcpy(eventBuffer[iter].data, storyChunk[iter].data);
//     }

//     /*
//      * Create dimension for the dataset append
//      */
//     const hsize_t dim[] = {numEvents};
    
//     /*
//      * Create the memory data type.
//      */
//     eventType = H5Tcreate(H5T_COMPOUND, sizeof(Event));
//     H5Tinsert(eventType, "timeStamp", HOFFSET(Event, timeStamp), H5T_NATIVE_ULONG);
//     H5Tinsert(eventType, "data", HOFFSET(Event, data), H5T_NATIVE_CHAR);

//     /*
//      * Create the file
//      */
//     hsize_t slabstart = 0;
//     hsize_t spacestart = 0;
//     hsize_t looptermination = dim[0];
//     hsize_t slabcount = 0;
//     if (H5Fis_hdf5(H5FILE_NAME))
//     {
//         std::cout << "The file exists and is an HDF5 file." << std::endl;
//         file = H5Fopen(H5FILE_NAME, H5F_ACC_RDONLY, H5P_DEFAULT);
//         if(H5Lexists(file, DATASET_NAME, H5P_DEFAULT)){

//             /*
//             * Open file and dataset
//             */
//             H5Fclose(file);
//             file = H5Fopen(H5FILE_NAME, H5F_ACC_RDWR, H5P_DEFAULT);
//             dataset = H5Dopen2(file, DATASET_NAME, H5P_DEFAULT);

//             /*
//             * Get the existing size of the dataset
//             */ 
//             dataspace_id = H5Dget_space(dataset);
//             hsize_t current_size[1];
//             H5Sget_simple_extent_dims(dataspace_id, current_size, NULL);
//             spacestart = current_size[0];
//             /*
//             * Define the new size of the dataset and extend it
//             */
//             hsize_t new_size[1] = {current_size[0] + dim[0]};
//             status = H5Dset_extent(dataset, new_size);

//             /* 
//             * Close the dataspace id and dataset
//             */
//             H5Sclose(dataspace_id);
//             H5Dclose(dataset);

//             /* 
//             * Open dataset and get dataspace id again
//             */
//             dataset = H5Dopen2(file, DATASET_NAME, H5P_DEFAULT);
//             space = H5Dget_space(dataset);
//         }
//         else{
//             /*
//             * Create the data space.
//             */
//             H5Fclose(file);
//             file = H5Fopen(H5FILE_NAME, H5F_ACC_RDWR, H5P_DEFAULT);
//             const hsize_t max_dim[] = {H5S_UNLIMITED};
//             space = H5Screate_simple(DATASET_RANK, dim, max_dim );

//             /*
//             * Enable chunking and chunk caching for the datset
//             */
//             dcpl_id = H5Pcreate(H5P_DATASET_CREATE);
//             status = H5Pset_chunk(dcpl_id, 1, chunk_dims);

//             /*
//             * Create the dataset.
//             */
//             dataset = H5Dcreate2(file, DATASET_NAME, eventType, space, H5P_DEFAULT, dcpl_id, H5P_DEFAULT);

//         }
//     }
//     else
//     {
//         file = H5Fcreate(H5FILE_NAME, H5F_ACC_TRUNC, H5P_DEFAULT, H5P_DEFAULT);
    
//         /*
//         * Create the data space.
//         */
//         const hsize_t max_dim[] = {H5S_UNLIMITED};
//         space = H5Screate_simple(DATASET_RANK, dim, max_dim );

//         /*
//         * Enable chunking and chunk caching for the datset
//         */
//         dcpl_id = H5Pcreate(H5P_DATASET_CREATE);
//         status = H5Pset_chunk(dcpl_id, 1, chunk_dims);

//         /*
//         * Create the dataset.
//         */
//         dataset = H5Dcreate2(file, DATASET_NAME, eventType, space, H5P_DEFAULT, dcpl_id, H5P_DEFAULT);
//     }

//     /*
//      * Write data to the dataset using hyperslab
//      */
//     hsize_t slab_start[] = {0};
//     hsize_t space_start[] = {spacestart};
//     hsize_t slab_count[1] = {dim[0]};
//     memorySpace = H5Screate_simple(DATASET_RANK, slab_count, NULL);
//     status = H5Sselect_hyperslab(memorySpace, H5S_SELECT_SET, slab_start, NULL, slab_count, NULL);
//     status = H5Sselect_hyperslab(space, H5S_SELECT_SET, space_start, NULL, slab_count, NULL);
//     status = H5Dwrite(dataset, eventType, memorySpace, space, H5P_DEFAULT, &eventBuffer[0]);
//     H5Sclose(memorySpace);
//     H5Sclose(space);

//     hsize_t attrcount = 0;
//     hsize_t chunksize = CHUNK_SIZE;
//     for (hsize_t iter = 0; iter < dim[0]; iter += CHUNK_SIZE) {
//         if(dim[0] - iter < CHUNK_SIZE){
//             chunksize = dim[0] - iter;
//         }
//         attrBuffer[attrcount].start = eventBuffer[iter].timeStamp;
//         attrBuffer[attrcount].end = eventBuffer[iter + chunksize - 1].timeStamp;
//         std::cout<<attrBuffer[attrcount].start<<"\t"<<attrBuffer[attrcount].end<<std::endl;
//         attrcount++;
//     }
    
//     /*
//      * Create datatype for the ChunkMetadata attribute.
//      */
//     at_tid = H5Tcreate(H5T_COMPOUND, sizeof(ChunkAttr));
//     H5Tinsert(at_tid, "start", HOFFSET(ChunkAttr, start), H5T_NATIVE_ULONG);
//     H5Tinsert(at_tid, "end", HOFFSET(ChunkAttr, end), H5T_NATIVE_ULONG);

//     if(H5Aexists_by_name(dataset, ".", ATTR_CHUNKMETADATA, H5P_DEFAULT)){
//         /*
//         * Open the attribute, get attribute id, type and space
//         */
//         std::cout<<"attribute exists"<<std::endl;
//         attribute_id = H5Aopen(dataset, ATTR_CHUNKMETADATA, H5P_DEFAULT);
//         attribute_type = H5Aget_type(attribute_id);
//         dataspace_a_id = H5Aget_space(attribute_id);
//         hsize_t ndims = H5Sget_simple_extent_npoints(dataspace_a_id);
//         H5Sclose(dataspace_a_id);
//         std::cout << " ndims: " << ndims << std::endl;
//         hsize_t adim[] = {ndims + attrcount};
//         attribute_data = (ChunkAttr *) malloc(adim[0] * sizeof(ChunkAttr));
        
//         /*
//         * Read the attribute data into the buffer and delete the attribute
//         */
//         H5Aread(attribute_id, attribute_type, attribute_data);
//         H5Aclose(attribute_id);
//         H5Adelete(dataset, ATTR_CHUNKMETADATA);

//         attr = H5Screate(H5S_SIMPLE);
//         herr_t ret  = H5Sset_extent_simple(attr, CHUNK_META_ATTR_RANK, adim, NULL);
//         attr1 = H5Acreate2(dataset, ATTR_CHUNKMETADATA, attribute_type, attr, H5P_DEFAULT, H5P_DEFAULT);

//         int64_t it = 0;
//         for(it = 0 ; it < attrcount ; it++ ){
//             attribute_data[ndims+it].start = attrBuffer[it].start;
//             attribute_data[ndims+it].end = attrBuffer[it].end;
//         }
//         ret = H5Awrite(attr1, attribute_type, attribute_data);

//         /*
//         * Modify MAX attribute
//         */
//         max_attr = H5Aopen(dataset, ATTR_MAX, H5P_DEFAULT);
//         H5Awrite(max_attr, H5T_NATIVE_ULONG, &attribute_data[adim[0] - 1].end);
//         std::cout<<"data written successfully"<<std::endl;
//         free(attribute_data);
//     }
//     else{
//         hsize_t adim[] = {attrcount};
//         attr = H5Screate(H5S_SIMPLE);
//         ret  = H5Sset_extent_simple(attr, CHUNK_META_ATTR_RANK, adim, NULL);

//         /*
//         * Create array attribute and write array attribute.
//         */
//         attr1 = H5Acreate2(dataset, ATTR_CHUNKMETADATA, at_tid, attr, H5P_DEFAULT, H5P_DEFAULT);
//         ret = H5Awrite(attr1, at_tid, attrBuffer);
//         std::cout<<"write attr"<<std::endl;
//         /*
//         * Create and write to Min and Max attribute.
//         */
//         at_tid = H5Tcreate(H5T_COMPOUND, sizeof(ChunkAttr));
//         adim[0] = {1};
//         attr = H5Screate_simple(1, adim, NULL);
//         std::cout<<"write min"<<std::endl;

//         min_attr = H5Acreate2(dataset, ATTR_MIN, H5T_NATIVE_ULONG, attr, H5P_DEFAULT, H5P_DEFAULT);
//         ret = H5Awrite(min_attr, H5T_NATIVE_ULONG, &eventBuffer[0].timeStamp);
//         std::cout<<"write max"<<std::endl;
//         max_attr = H5Acreate2(dataset, ATTR_MAX, H5T_NATIVE_ULONG, attr, H5P_DEFAULT, H5P_DEFAULT);
//         ret = H5Awrite(max_attr, H5T_NATIVE_ULONG, &eventBuffer[dim[0]-1].timeStamp);

//     }
//     std::cout<<"release resources"<<std::endl;
//     /*
//      * Release resources
//      */
//     free(attrBuffer);
//     free(eventBuffer);

//     H5Aclose(attr1);
//     H5Aclose(min_attr);
//     H5Aclose(max_attr);
//     H5Tclose(eventType);
//     H5Tclose(at_tid);
//     H5Sclose(attr);
//     H5Dclose(dataset);
//     H5Fclose(file);
//     std::cout<<"done resources"<<std::endl;
//     return 0;
// }

// // Append to existing dataset
// int appendToDataset(std::vector<Event> storyChunk, const char* FILE_NAME, const char* DATASET_NAME, const char* H5FILE_NAME) {

//     hid_t   file, dataset, space, memorySpace, eventType, plist_id, dataspace_id, at_tid, attribute_id, attribute_type, dataspace_a_id, attr, attr1, max_attr;
//     herr_t  status;
//     Event* eventBuffer;
//     ChunkAttr* attrBuffer;
//     ChunkAttr* attribute_data;
//     hsize_t chunk_size[1];

//     /*
//      * Number of events
//      */
//     const hsize_t numberOfEvents = storyChunk.size() - 1;

//     /*
//      * Allocate memory for events data
//      */
//     eventBuffer = (Event*) malloc(numberOfEvents * sizeof(Event));

//     /*
//      * Read data from storyChunk into buffer
//      */
//     for(int i = 0 ; i < numberOfEvents ; i++) {
//        eventBuffer[i].timeStamp = storyChunk[i].timeStamp;
//        strcpy(eventBuffer[i].data, storyChunk[i].data);
//     }

//     /*
//      * Create dimension for the dataset append
//      */
//     hsize_t dim[] = {numberOfEvents};

//     /*
//      * Create the memory data type.
//      */
//     eventType = H5Tcreate(H5T_COMPOUND, sizeof(Event));
//     H5Tinsert(eventType, "timeStamp", HOFFSET(Event, timeStamp), H5T_NATIVE_ULONG);
//     H5Tinsert(eventType, "data", HOFFSET(Event, data), H5T_NATIVE_CHAR);
    
//     /*
//      * Open file and dataset
//      */
//     file = H5Fopen(H5FILE_NAME, H5F_ACC_RDWR, H5P_DEFAULT);
//     dataset = H5Dopen2(file, DATASET_NAME, H5P_DEFAULT);
//     plist_id = H5Dget_create_plist(dataset);
//     int rank = H5Pget_chunk(plist_id, 1, NULL);
//     H5Pget_chunk(plist_id, 1, chunk_size);
//     std::cout<<"Chunk size: "<<chunk_size[0]<<std::endl;

//     /*
//      * Get the existing size of the dataset
//      */ 
//     dataspace_id = H5Dget_space(dataset);
//     hsize_t current_size[1];
//     H5Sget_simple_extent_dims(dataspace_id, current_size, NULL);

//     /*
//      * Define the new size of the dataset and extend it
//      */
//     hsize_t new_size[1] = {current_size[0] + dim[0]};
//     status = H5Dset_extent(dataset, new_size);

//     /* 
//      * Close the dataspace id and dataset
//      */
//     H5Sclose(dataspace_id);
//     H5Dclose(dataset);

//     /* 
//      * Open dataset and get dataspace id again
//      */
//     dataset = H5Dopen2(file, DATASET_NAME, H5P_DEFAULT);
//     dataspace_id = H5Dget_space(dataset);
//     hsize_t _size[1];
//     H5Sget_simple_extent_dims(dataspace_id, _size, NULL);
    
//     /*
//      * Allocate memory for events data
//      */
//     attrBuffer = (ChunkAttr*) malloc(((numberOfEvents / chunk_size[0]) + 1) * sizeof(ChunkAttr));
//     std::cout<<"attrbuffer"<<((numberOfEvents / chunk_size[0]) + 1)<<std::endl;
//     /*
//      * Write data to the dataset using hyperslab
//      */
//     hsize_t slab_start[] = {0};
//     hsize_t space_start[] = {current_size[0]};
//     hsize_t slab_count[1] = {chunk_size[0]};
//     memorySpace = H5Screate_simple(DATASET_RANK, slab_count, NULL);
//     status = H5Sselect_hyperslab(memorySpace, H5S_SELECT_SET, slab_start, NULL, slab_count, NULL);

//     hsize_t attrcount = 0;
//     hsize_t iter = 0;
//     hsize_t datasize = 0;
//     for (iter = current_size[0] ; iter < new_size[0] ; iter += chunk_size[0]) {
//         space_start[0] = iter;
//         if(new_size[0] - iter < chunk_size[0]){
//             slab_count[0] = new_size[0] - iter;
//             memorySpace = H5Screate_simple(DATASET_RANK, slab_count, NULL);
//             status = H5Sselect_hyperslab(memorySpace, H5S_SELECT_SET, slab_start, NULL, slab_count, NULL);
//         }

//         status = H5Sselect_hyperslab(dataspace_id, H5S_SELECT_SET, space_start, NULL, slab_count, NULL);
//         status = H5Dwrite(dataset, eventType, memorySpace, dataspace_id, H5P_DEFAULT, &eventBuffer[datasize]);
        
//         /*
//         * Add chunk's start and end timeStamp to attribute table(data)
//         */
//         attrBuffer[attrcount].start = eventBuffer[datasize].timeStamp;
//         attrBuffer[attrcount].end = eventBuffer[datasize + slab_count[0] - 1].timeStamp;
//         datasize += chunk_size[0];
//         attrcount++;
//         std::cout << "attrcount: " << attrcount << std::endl;
//     }
//     free(eventBuffer);

//     /*
//      * Create dataspace for the ChunkMetadata attribute.
//      */
//     at_tid = H5Tcreate(H5T_COMPOUND, sizeof(ChunkAttr));
//     H5Tinsert(at_tid, "start", HOFFSET(ChunkAttr, start), H5T_NATIVE_ULONG);
//     H5Tinsert(at_tid, "end", HOFFSET(ChunkAttr, end), H5T_NATIVE_ULONG);

//     /*
//      * Open the attribute, get attribute id, type and space
//      */
//     attribute_id = H5Aopen(dataset, ATTR_CHUNKMETADATA, H5P_DEFAULT);
//     attribute_type = H5Aget_type(attribute_id);
//     dataspace_a_id = H5Aget_space(attribute_id);
//     hsize_t ndims = H5Sget_simple_extent_npoints(dataspace_a_id);
//     H5Sclose(dataspace_a_id);
//     std::cout << " ndims: " << ndims << std::endl;
//     hsize_t adim[] = {ndims + attrcount};
//     attribute_data = (ChunkAttr *) malloc(adim[0] * sizeof(ChunkAttr));
    
//     /*
//      * Read the attribute data into the buffer and delete the attribute
//      */
//     H5Aread(attribute_id, attribute_type, attribute_data);
//     H5Aclose(attribute_id);
//     H5Adelete(dataset, ATTR_CHUNKMETADATA);

//     attr = H5Screate(H5S_SIMPLE);
//     herr_t ret  = H5Sset_extent_simple(attr, CHUNK_META_ATTR_RANK, adim, NULL);
//     attr1 = H5Acreate2(dataset, ATTR_CHUNKMETADATA, attribute_type, attr, H5P_DEFAULT, H5P_DEFAULT);

//     iter = 0;
//     for(iter = 0 ; iter < attrcount ; iter++ ){
//         attribute_data[ndims+iter].start = attrBuffer[iter].start;
//         attribute_data[ndims+iter].end = attrBuffer[iter].end;
//     }
//     ret = H5Awrite(attr1, attribute_type, attribute_data);

//     /*
//      * Modify MAX attribute
//      */
//     max_attr = H5Aopen(dataset, ATTR_MAX, H5P_DEFAULT);
//     H5Awrite(max_attr, H5T_NATIVE_ULONG, &attribute_data[adim[0] - 1].end);
//     std::cout<<"data written successfully"<<std::endl;
//     /*
//      * Release resources
//      */
//     free(attrBuffer);
//     free(attribute_data);
//     H5Sclose(memorySpace);
//     H5Aclose(max_attr);
//     H5Tclose(eventType);
//     H5Dclose(dataset);
//     H5Fclose(file);

//     return 0;
// }









#include <iostream>
#include <fstream>
#include <sstream>
#include <string>
#include <cstring>
#include <vector>
#include <event.h>
#include <hdf5.h>
#include <chunkattr.h>

#define DATASET_RANK 1 // Dataset dimension
#define ATTRIBUTE_CHUNKMETADATA "ChunkMetadata"
#define ATTRIBUTE_DATASET_MIN "Min"
#define ATTRIBUTE_DATASET_MAX "Max"
#define ATTRIBUTE_TOTAL_DATASET_STORY_EVENTS "TotalStoryEvents"
#define ATTRIBUTE_CHUNKMETADATA_RANK 1
#define DEBUG 0 // Set to 1 if you want to print H5 error messages to console
#define CHUNK_SIZE 10000 // Number of events equal to page size of 4MB

/*
 * Write data to storyDataset. 
 * return 0 -> write is successful
 * returns -1 -> write failure
 */
int writeStoryChunk(std::vector<Event> storyChunk, const char* STORY, const char* CHRONICLE) {

    // Disable automatic printing of HDF5 error stack to console
    if(!DEBUG){
        H5Eset_auto(H5E_DEFAULT, NULL, NULL);
    }

    hid_t   ChronicleH5, storyDataset, storyDatasetSpace, chunkPropId, hyperslabMemorySpace, eventType, chunkmetaAttribute, attr, attr1, attr_DatasetMin, attr_DatasetMax, attr_DatasetTotalStoryEvents;
    hid_t   attributeId, attributeType, attributeDataSpace;
    herr_t  status, ret;

    Event* eventBuffer;
    ChunkAttr* attributeDataBuffer;
    ChunkAttr* extendAttributeDataBuffer;

    /* 
     * Chunk Dimension and number of events in a story chunk
     */
    hsize_t chunkDims[1] = {CHUNK_SIZE};
    const hsize_t numberOfEvents = storyChunk.size() - 1;

    /*
     * Allocate memory for events buffer
     * TODO: Modification required in case of variable sized events
     */
    eventBuffer = (Event*) malloc(numberOfEvents * sizeof(Event));
    if(eventBuffer == NULL){
        return -1;
    }
    std::cout<<"EventBuffer\n";
    /*
     * Allocate memory for attribute buffer
     */
    attributeDataBuffer = (ChunkAttr*) malloc(((numberOfEvents / CHUNK_SIZE) + 1) * sizeof(ChunkAttr));
    if(attributeDataBuffer == NULL){
        free(eventBuffer);
        return -1;
    }
    std::cout<<"attributebuffer\n";
    /*
     * Read data from storyChunk into eventBuffer
     */
    for(auto event = 0 ; event < numberOfEvents ; event++) {
       eventBuffer[event].timeStamp = storyChunk[event].timeStamp;
       strcpy(eventBuffer[event].data, storyChunk[event].data);
    }
    std::cout<<"Copy to buffer done\n";
    /*
     * Dimensions for the storyDataset
     */
    const hsize_t storyChunkDims[] = {storyChunk.size() - 1};

    /*
     * User defined compound datatype - consists "timeStamp" and "data"
     */
    herr_t timeStampError, dataError;
    eventType = H5Tcreate(H5T_COMPOUND, sizeof(Event));
    timeStampError = H5Tinsert(eventType, "timeStamp", HOFFSET(Event, timeStamp), H5T_NATIVE_ULONG);
    dataError = H5Tinsert(eventType, "data", HOFFSET(Event, data), H5T_NATIVE_CHAR);
    if(eventType < 0 || dataError < 0 || timeStampError < 0){
        if(eventType >=0 )  H5Tclose(eventType);
        free(attributeDataBuffer);
        free(eventBuffer);
        return -1;
    }

    hsize_t storyDatasetSpaceStart = 0;
    hsize_t newStorySize[1];

    /*
     * Check if the ChronicleH5 already exists
     */
    if (H5Fis_hdf5(CHRONICLE) > 0)
    {
        /*
         * Open ChronicleH5 and check if the storyDataset exists
         */

        ChronicleH5 = H5Fopen(CHRONICLE, H5F_ACC_RDONLY, H5P_DEFAULT);
        if(ChronicleH5 < 0){
            free(attributeDataBuffer);
            free(eventBuffer);
            H5Tclose(eventType);
            return -1;
        }
        if(H5Lexists(ChronicleH5, STORY, H5P_DEFAULT) > 0){
            /*
             * Open ChronicleH5 and storyDataset
             */
            H5Fclose(ChronicleH5);
            ChronicleH5 = H5Fopen(CHRONICLE, H5F_ACC_RDWR, H5P_DEFAULT);

            storyDataset = H5Dopen2(ChronicleH5, STORY, H5P_DEFAULT);

            /*
             * Get the existing size of the storyDataset
             */
            attributeId = H5Aopen(storyDataset, ATTRIBUTE_TOTAL_DATASET_STORY_EVENTS, H5P_DEFAULT);
            attributeType = H5Aget_type(attributeId);
            attributeDataSpace = H5Aget_space(attributeId);

            hsize_t totalStoryEvents;
            status = H5Aread(attributeId, attributeType, &totalStoryEvents);

            if(status < 0 || attributeDataSpace < 0 || attributeId < 0 || attributeType < 0 || storyDataset < 0 || ChronicleH5 < 0){
                if(attributeId >= 0)  H5Aclose(attributeId);
                if(attributeDataSpace >= 0)  H5Sclose(attributeDataSpace);
                if(attributeType >= 0)  H5Tclose(attributeType);
                if(storyDataset >= 0)  H5Dclose(storyDataset);
                if(ChronicleH5 >= 0)  H5Fclose(ChronicleH5);
                free(attributeDataBuffer);
                free(eventBuffer);
                H5Tclose(eventType);
                return -1;
            }

            H5Tclose(attributeType);
            H5Sclose(attributeDataSpace);
            H5Aclose(attributeId);

            /*
            * Define the new size of the storyDataset and extend it
            */
            storyDatasetSpaceStart = totalStoryEvents;
            newStorySize[0] = {totalStoryEvents + storyChunkDims[0]};
            status = H5Dset_extent(storyDataset, newStorySize);
            if(status < 0 ){
                free(attributeDataBuffer);
                free(eventBuffer);
                H5Tclose(eventType);
                H5Dclose(storyDataset);
                H5Fclose(ChronicleH5);
                return -1;
            }

            /* 
            * Commit new size of the storyDataset. Close the storyDataset
            */
            H5Dclose(storyDataset);

            /* 
            * Open storyDataset and get extended dataspace
            */
            storyDataset = H5Dopen2(ChronicleH5, STORY, H5P_DEFAULT);
            storyDatasetSpace = H5Dget_space(storyDataset);

            if(storyDatasetSpace < 0 || storyDataset < 0){
                if(storyDatasetSpace >= 0)  H5Sclose(storyDatasetSpace);
                if(storyDataset >= 0)  H5Dclose(storyDataset);
                free(attributeDataBuffer);
                free(eventBuffer);
                H5Tclose(eventType);
                H5Fclose(ChronicleH5);
                return -1;
            }
        }

        /*
         * Create the storyDataset
         */
        else{
            std::cout << "Dataset not found..." << std::endl;
            H5Fclose(ChronicleH5);
            ChronicleH5 = H5Fopen(CHRONICLE, H5F_ACC_RDWR, H5P_DEFAULT);

            /*
             * Enable chunking for the storyDataset
             */
            chunkPropId = H5Pcreate(H5P_DATASET_CREATE);
            status = H5Pset_chunk(chunkPropId, 1, chunkDims);

            /*
             * Create the storyDataset.
             */
            const hsize_t datasetMaxDims[] = {H5S_UNLIMITED};
            storyDatasetSpace = H5Screate_simple(DATASET_RANK, storyChunkDims, datasetMaxDims );
            if(storyDatasetSpace < 0 || ChronicleH5 < 0 || status < 0 || chunkPropId < 0){
                if(chunkPropId >= 0)    H5Pclose(chunkPropId);
                if(storyDatasetSpace >= 0)  H5Sclose(storyDatasetSpace);
                if(ChronicleH5 >= 0)  H5Fclose(ChronicleH5);
                free(attributeDataBuffer);
                free(eventBuffer);
                H5Tclose(eventType);
                return -1;
            }

            storyDataset = H5Dcreate2(ChronicleH5, STORY, eventType, storyDatasetSpace, H5P_DEFAULT, chunkPropId, H5P_DEFAULT);
            if(storyDataset < 0){
                free(attributeDataBuffer);
                free(eventBuffer);
                H5Tclose(eventType);
                H5Pclose(chunkPropId);
                H5Sclose(storyDatasetSpace);
                H5Fclose(ChronicleH5);
                return -1;
            }

        }
    }
    /*
     * Create the ChronicleH5 and storyDataset
     */
    else
    {
        ChronicleH5 = H5Fcreate(CHRONICLE, H5F_ACC_TRUNC, H5P_DEFAULT, H5P_DEFAULT);
        /*
         * Enable chunking for the storyDataset
         */
        chunkPropId = H5Pcreate(H5P_DATASET_CREATE);
        status = H5Pset_chunk(chunkPropId, 1, chunkDims);

        /*
         * Create the storyDataset.
         */
        const hsize_t datasetMaxDims[] = {H5S_UNLIMITED};
        storyDatasetSpace = H5Screate_simple(DATASET_RANK, storyChunkDims, datasetMaxDims );
        if(storyDatasetSpace < 0 || ChronicleH5 < 0 || status < 0 || chunkPropId < 0){
            if(chunkPropId >= 0)    H5Pclose(chunkPropId);
            if(storyDatasetSpace >= 0)  H5Sclose(storyDatasetSpace);
            if(ChronicleH5 >= 0)  H5Fclose(ChronicleH5);
            free(attributeDataBuffer);
            free(eventBuffer);
            H5Tclose(eventType);
            return -1;
        }

        storyDataset = H5Dcreate2(ChronicleH5, STORY, eventType, storyDatasetSpace, H5P_DEFAULT, chunkPropId, H5P_DEFAULT);
        if(storyDataset < 0){
            free(attributeDataBuffer);
            free(eventBuffer);
            H5Tclose(eventType);
            H5Pclose(chunkPropId);
            H5Sclose(storyDatasetSpace);
            H5Fclose(ChronicleH5);
            return -1;
        }
    }

    /*
     * Write data to the storyDataset
     */
    hsize_t datasetHyperslabStart[] = {0};
    hsize_t storySpaceStart[] = {storyDatasetSpaceStart};
    hyperslabMemorySpace = H5Screate_simple(DATASET_RANK, storyChunkDims, NULL);

    herr_t memSpaceErr, datasetSpaceError;
    memSpaceErr = H5Sselect_hyperslab(hyperslabMemorySpace, H5S_SELECT_SET, datasetHyperslabStart, NULL, storyChunkDims, NULL);
    datasetSpaceError = H5Sselect_hyperslab(storyDatasetSpace, H5S_SELECT_SET, storySpaceStart, NULL, storyChunkDims, NULL);
    if(memSpaceErr < 0 || datasetSpaceError < 0 || hyperslabMemorySpace < 0){
        if(hyperslabMemorySpace >= 0)  H5Sclose(hyperslabMemorySpace);
        if(storyDatasetSpace >= 0)  H5Sclose(storyDatasetSpace);
        free(attributeDataBuffer);
        free(eventBuffer);
        H5Tclose(eventType);
        H5Dclose(storyDataset);
        H5Fclose(ChronicleH5);
        return -1;
    }

    status = H5Dwrite(storyDataset, eventType, hyperslabMemorySpace, storyDatasetSpace, H5P_DEFAULT, &eventBuffer[0]);
    if(status < 0){
        H5Sclose(hyperslabMemorySpace);
        H5Sclose(storyDatasetSpace);
        free(attributeDataBuffer);
        free(eventBuffer);
        H5Tclose(eventType);
        H5Dclose(storyDataset);
        H5Fclose(ChronicleH5);
        return -1;
    }

    H5Sclose(hyperslabMemorySpace);
    H5Sclose(storyDatasetSpace);

    hsize_t attributeCount = 0;
    hsize_t chunksize = CHUNK_SIZE;
    for (hsize_t eventIndex = 0; eventIndex < storyChunkDims[0]; eventIndex += CHUNK_SIZE) {
        if(storyChunkDims[0] - eventIndex < CHUNK_SIZE){
            chunksize = storyChunkDims[0] - eventIndex;
        }
        attributeDataBuffer[attributeCount].start = eventBuffer[eventIndex].timeStamp;
        attributeDataBuffer[attributeCount].end = eventBuffer[eventIndex + chunksize - 1].timeStamp;
        attributeCount++;
    }

    /*
     * Create datatype for the ChunkMetadata attribute.
     */
    herr_t startError, endError, attrMaxError, attrStoryEventsError, attrMinError, attrError;
    chunkmetaAttribute = H5Tcreate(H5T_COMPOUND, sizeof(ChunkAttr));
    startError = H5Tinsert(chunkmetaAttribute, "start", HOFFSET(ChunkAttr, start), H5T_NATIVE_ULONG);
    endError = H5Tinsert(chunkmetaAttribute, "end", HOFFSET(ChunkAttr, end), H5T_NATIVE_ULONG);
    if(chunkmetaAttribute < 0 || endError < 0 || startError < 0){
        free(attributeDataBuffer);
        free(eventBuffer);
        H5Tclose(eventType);
        H5Dclose(storyDataset);
        H5Fclose(ChronicleH5);
        return -1;
    }

    if(H5Aexists_by_name(storyDataset, ".", ATTRIBUTE_CHUNKMETADATA, H5P_DEFAULT) > 0){
        /*
        * Open the attribute, get attribute id, type and space
        */
        attributeId = H5Aopen(storyDataset, ATTRIBUTE_CHUNKMETADATA, H5P_DEFAULT);
        attributeType = H5Aget_type(attributeId);
        attributeDataSpace = H5Aget_space(attributeId);
        hsize_t attributeChunkMetadataDims = H5Sget_simple_extent_npoints(attributeDataSpace);
        H5Sclose(attributeDataSpace);

        hsize_t attributeDims[] = {attributeChunkMetadataDims + attributeCount};
        extendAttributeDataBuffer = (ChunkAttr *) malloc(attributeDims[0] * sizeof(ChunkAttr));

        /*
         * Read the attribute data into the buffer and delete the attribute
         */
        status = H5Aread(attributeId, attributeType, extendAttributeDataBuffer);
        if(status < 0 || attributeId < 0 || attributeType < 0 || extendAttributeDataBuffer == NULL || attributeChunkMetadataDims == HSIZE_UNDEF){
            if(attributeId >= 0)  H5Aclose(attributeId);
            if(attributeType >= 0)  H5Tclose(attributeType);
            if(extendAttributeDataBuffer != NULL)   free(extendAttributeDataBuffer);
            free(attributeDataBuffer);
            free(eventBuffer);
            H5Tclose(chunkmetaAttribute);
            H5Tclose(eventType);
            H5Dclose(storyDataset);
            H5Fclose(ChronicleH5);
            return -1;
        }

        H5Aclose(attributeId);
        herr_t deleteError = H5Adelete(storyDataset, ATTRIBUTE_CHUNKMETADATA);

        attr = H5Screate(H5S_SIMPLE);
        ret  = H5Sset_extent_simple(attr, ATTRIBUTE_CHUNKMETADATA_RANK, attributeDims, NULL);

        attr1 = H5Acreate2(storyDataset, ATTRIBUTE_CHUNKMETADATA, attributeType, attr, H5P_DEFAULT, H5P_DEFAULT);

        if(deleteError < 0 || attr < 0 || ret < 0 || attr1 < 0){
            if(attr >= 0)   H5Sclose(attr);
            if(attr1 >= 0)  H5Aclose(attr1);
            free(attributeDataBuffer);
            free(eventBuffer);
            free(extendAttributeDataBuffer);
            H5Tclose(attributeType);
            H5Tclose(chunkmetaAttribute);
            H5Tclose(eventType);
            H5Dclose(storyDataset);
            H5Fclose(ChronicleH5);
            return -1;
        }

        for(auto index = 0 ; index < attributeCount ; index++ ){
            extendAttributeDataBuffer[attributeChunkMetadataDims + index].start = attributeDataBuffer[index].start;
            extendAttributeDataBuffer[attributeChunkMetadataDims + index].end = attributeDataBuffer[index].end;
        }
        ret = H5Awrite(attr1, attributeType, extendAttributeDataBuffer);
 
        /*
         * Modify MAX attribute
         */
        attr_DatasetMax = H5Aopen(storyDataset, ATTRIBUTE_DATASET_MAX, H5P_DEFAULT);
        attrMaxError = H5Awrite(attr_DatasetMax, H5T_NATIVE_ULONG, &extendAttributeDataBuffer[attributeDims[0] - 1].end);

        attr_DatasetTotalStoryEvents = H5Aopen(storyDataset, ATTRIBUTE_TOTAL_DATASET_STORY_EVENTS, H5P_DEFAULT);
        attrStoryEventsError = H5Awrite(attr_DatasetTotalStoryEvents, H5T_NATIVE_ULONG, &newStorySize[0]);

        if(ret < 0 || attr_DatasetMax < 0 || attr_DatasetTotalStoryEvents < 0 || attrMaxError < 0 || attrStoryEventsError < 0){
            if(attr_DatasetMax >= 0)    H5Aclose(attr_DatasetMax);
            if(attr_DatasetTotalStoryEvents >= 0)    H5Aclose(attr_DatasetTotalStoryEvents);

            free(attributeDataBuffer);
            free(eventBuffer);
            free(extendAttributeDataBuffer);

            H5Sclose(attr);
            H5Aclose(attr1);
            H5Tclose(attributeType);
            H5Tclose(chunkmetaAttribute);
            H5Tclose(eventType);
            H5Dclose(storyDataset);
            H5Fclose(ChronicleH5);
            return -1;
        }

        // Release extendAttributeBuffer memory
        free(extendAttributeDataBuffer);
    }
    else{
        hsize_t attributeDims[] = {attributeCount};
        attr = H5Screate(H5S_SIMPLE);
        ret  = H5Sset_extent_simple(attr, ATTRIBUTE_CHUNKMETADATA_RANK, attributeDims, NULL);

        /*
         * Create array attribute and write array attribute.
         */
        attr1 = H5Acreate2(storyDataset, ATTRIBUTE_CHUNKMETADATA, chunkmetaAttribute, attr, H5P_DEFAULT, H5P_DEFAULT);
        attrError = H5Awrite(attr1, chunkmetaAttribute, attributeDataBuffer);

        /*
         * Create and write to Min and Max and totalStoryEvents attribute.
         */
        attributeDims[0] = {1};
        attr = H5Screate_simple(1, attributeDims, NULL);

        attr_DatasetMin = H5Acreate2(storyDataset, ATTRIBUTE_DATASET_MIN, H5T_NATIVE_ULONG, attr, H5P_DEFAULT, H5P_DEFAULT);
        attrMinError = H5Awrite(attr_DatasetMin, H5T_NATIVE_ULONG, &eventBuffer[0].timeStamp);

        attr_DatasetMax = H5Acreate2(storyDataset, ATTRIBUTE_DATASET_MAX, H5T_NATIVE_ULONG, attr, H5P_DEFAULT, H5P_DEFAULT);
        attrMaxError = H5Awrite(attr_DatasetMax, H5T_NATIVE_ULONG, &eventBuffer[storyChunkDims[0]-1].timeStamp);

        attr_DatasetTotalStoryEvents = H5Acreate2(storyDataset, ATTRIBUTE_TOTAL_DATASET_STORY_EVENTS, H5T_NATIVE_ULONG, attr, H5P_DEFAULT, H5P_DEFAULT);
        attrStoryEventsError = H5Awrite(attr_DatasetTotalStoryEvents, H5T_NATIVE_ULONG, &storyChunkDims[0]);
        if(attrStoryEventsError < 0 || attr_DatasetTotalStoryEvents < 0 || attrMinError < 0 || attr_DatasetMin < 0 || attrMaxError < 0 || attr_DatasetMax < 0 || attr < 0 || attr1 < 0 || attrError < 0)
        {
            if(attr_DatasetTotalStoryEvents >= 0)   H5Aclose(attr_DatasetTotalStoryEvents);
            if(attr_DatasetMax >= 0)    H5Aclose(attr_DatasetMax);
            if(attr_DatasetMin >= 0)    H5Aclose(attr_DatasetMin);
            if(attr1 >= 0)  H5Aclose(attr1);
            if(attr >= 0)   H5Sclose(attr);
            free(attributeDataBuffer);
            free(eventBuffer);
            H5Tclose(chunkmetaAttribute);
            H5Tclose(eventType);
            H5Dclose(storyDataset);
            H5Fclose(ChronicleH5);
            return 1;
        }
    }

    /*
     * Release resources
     */
    free(attributeDataBuffer);
    free(eventBuffer);

    H5Aclose(attr1);
    H5Sclose(attr);
    H5Sclose(attributeDataSpace);
    H5Aclose(attributeId);
    H5Tclose(attributeType);
    H5Aclose(attr_DatasetMin);
    H5Aclose(attr_DatasetMax);
    H5Aclose(attr_DatasetTotalStoryEvents);
    H5Tclose(eventType);
    H5Tclose(chunkmetaAttribute);
    H5Pclose(chunkPropId);
    H5Dclose(storyDataset);
    H5Fclose(ChronicleH5);

    return 0;
}







#include <iostream>
#include <string>
#include <vector>
#include <hdf5.h>
#include <read.h>
#include <event.h>
#include <chunkattr.h>

#define DATASET_RANK 1 // Dataset dimension
#define ATTRIBUTE_CHUNKMETADATA "ChunkMetadata"
#define ATTRIBUTE_DATASET_MIN "Min"
#define ATTRIBUTE_DATASET_MAX "Max"
#define ATTRIBUTE_TOTAL_DATASET_STORY_EVENTS "TotalStoryEvents"
#define DEBUG 1

// Helper function
int64_t searchChunkmetadata(ChunkAttr* chunkData, uint64_t timestampToSearch, int64_t totalChunks, int64_t chunkStart) {
    int64_t startChunk = chunkStart;
    int64_t endChunk = totalChunks - 1;
    int64_t currentChunk = INT_MIN;
    while (startChunk <= endChunk) {
        currentChunk = startChunk + (endChunk - startChunk) / 2;
        if (chunkData[currentChunk].startTimeStamp <= timestampToSearch && timestampToSearch <= chunkData[currentChunk].endTimeStamp) {
            break;
        }
        else if (chunkData[currentChunk].startTimeStamp > timestampToSearch) {
            endChunk = currentChunk - 1;
        }
        else {
            startChunk = currentChunk + 1;
        }
    }
    return currentChunk;
}

// Read data from story dataset for given Chronicle. Returns empty vector and status as -1 if range not within limits or range not found, else returns vector filled with Events data and status as 0
std::pair<int, std::vector<Event>> readFromDataset(std::pair<uint64_t, uint64_t> range, const char* STORY, const char* CHRONICLE){

    // Disable automatic printing of HDF5 error stack
    if(!DEBUG){
        H5Eset_auto(H5E_DEFAULT, NULL, NULL);
    }

    std::pair<int, std::vector<Event>> readStory;
    std::vector<Event> resultEvents;
    std::vector<Event> empVec = {};
    hid_t   chronicle, story, storyDatasetSpace, eventType;
    hsize_t dims_out[DATASET_RANK];
    herr_t  status;
    ChunkAttr* attributeDataBuffer;
    Event* eventBuffer;

    /*
     * read data from the story
     */
    chronicle = H5Fopen(CHRONICLE, H5F_ACC_RDONLY, H5P_DEFAULT);
    story = H5Dopen2(chronicle, STORY, H5P_DEFAULT);
    storyDatasetSpace  = H5Dget_space(story);
    status = H5Sget_simple_extent_dims(storyDatasetSpace, dims_out, NULL);
    std::cout<<dims_out[0]<<std::endl;

    if(chronicle < 0 || story < 0 || status < 0 || storyDatasetSpace < 0){
        H5Sclose(storyDatasetSpace);
        H5Dclose(story);
        H5Fclose(chronicle);
        return std::make_pair(-1, empVec);
    }
    // H5Sclose(storyDatasetSpace);

    /*
     * Open the attribute chunkmetadata
     * Get the attribute type and storyDatasetSpace
     * Get the number of DATASET_RANK of the storyDatasetSpace
     * Get the story creation property list for chunksize information
     * Read the attribute data into the buffer
     */
    hid_t attributeId = H5Aopen(story, ATTRIBUTE_CHUNKMETADATA, H5P_DEFAULT);

    hid_t attributeType = H5Aget_type(attributeId);
    hid_t attributeDataSpace = H5Aget_space(attributeId);

    hsize_t attributeDims = H5Sget_simple_extent_npoints(attributeDataSpace);

    hid_t chunkPropId = H5Dget_create_plist(story);
    hsize_t attributeChunkMetadataDims[1];
    herr_t getChunkError = H5Pget_chunk(chunkPropId, 1, attributeChunkMetadataDims);
    hsize_t CHUNK_SIZE = attributeChunkMetadataDims[0];
    std::cout<<"CHUNK_SIZE: "<<CHUNK_SIZE<<std::endl;
    attributeDataBuffer = (ChunkAttr *) malloc(attributeDims * sizeof(ChunkAttr));
    herr_t readChunkAttributeErr = H5Aread(attributeId, attributeType, attributeDataBuffer);

    if(attributeId < 0 || attributeDataBuffer == NULL || attributeType < 0 || attributeDataSpace < 0 || chunkPropId < 0 || getChunkError < 0 || readChunkAttributeErr){
        if(attributeDataBuffer != NULL) free(attributeDataBuffer);
        H5Tclose(attributeType);
        H5Sclose(attributeDataSpace);
        H5Aclose(attributeId);
        H5Pclose(chunkPropId);
        H5Dclose(story);
        H5Fclose(chronicle);
        return std::make_pair(-1, empVec);
    }

    H5Tclose(attributeType);
    H5Sclose(attributeDataSpace);
    H5Aclose(attributeId);
    H5Pclose(chunkPropId);

    std::pair<int64_t, int64_t> chunksToRead = {INT_MIN , INT_MIN};
    /*
     * Find the starting chunk index
     */
    chunksToRead.first = searchChunkmetadata(attributeDataBuffer, range.first, attributeDims, 0);
    if(chunksToRead.first != INT_MIN){
        chunksToRead.second = searchChunkmetadata(attributeDataBuffer, range.second, attributeDims, chunksToRead.first);
    }
    std::cout<<"Chunks to read: "<<chunksToRead.first<<" "<<chunksToRead.second<<std::endl;
    /*
     * Check for the range of requested query of chunks are not found
     */
    if(chunksToRead.second == INT_MIN || chunksToRead.first == INT_MIN){
        free(attributeDataBuffer);
        H5Dclose(story);
        H5Fclose(chronicle);
        return std::make_pair(-1, empVec);
    }

    /*
     * Allocate memory for events buffer
     * TODO: Modification required in case of variable sized events
     */
    eventBuffer = (Event*) malloc(CHUNK_SIZE * sizeof(Event));

    herr_t timeStampError, dataError;
    eventType = H5Tcreate(H5T_COMPOUND, sizeof(Event));
    timeStampError = H5Tinsert(eventType, "timeStamp", HOFFSET(Event, timeStamp), H5T_NATIVE_ULLONG);
    dataError = H5Tinsert(eventType, "data", HOFFSET(Event, data), H5T_NATIVE_CHAR);

    if(eventType < 0 || dataError < 0 || timeStampError < 0 || eventBuffer == NULL){
        if(eventBuffer != NULL) free(eventBuffer);
        if(eventType >=0 )  H5Tclose(eventType);
        free(attributeDataBuffer);
        H5Dclose(story);
        H5Fclose(chronicle);
        return std::make_pair(-1, empVec);
    }
    // free(attributeDataBuffer);

    /* 
     * Create a memory storyDatasetSpace to hold the chunk data 
     */
    hsize_t datasetHyperslabStart[] = {0};
    hsize_t storyChunkDims[] = {CHUNK_SIZE};
    herr_t memSpaceErr, datasetSpaceError;
    storyDatasetSpace  = H5Dget_space(story);
    hid_t hyperslabMemorySpace = H5Screate_simple(1, storyChunkDims, NULL);
    memSpaceErr = H5Sselect_hyperslab(hyperslabMemorySpace, H5S_SELECT_SET, datasetHyperslabStart, NULL, storyChunkDims, NULL);

    if(memSpaceErr < 0 || hyperslabMemorySpace < 0 || storyDatasetSpace < 0){
        if(storyDatasetSpace >= 0)  H5Sclose(storyDatasetSpace);
        if(hyperslabMemorySpace >= 0) H5Sclose(hyperslabMemorySpace);
        free(eventBuffer);
        free(attributeDataBuffer);
        H5Tclose(eventType);
        H5Dclose(story);
        H5Fclose(chronicle);
        return std::make_pair(-1, empVec);
    }

    try{
        /* 
        * Read the first chunk
        */
        hsize_t chunkOffset[] = {hsize_t (chunksToRead.first * CHUNK_SIZE)};
        std::cout<<"Chunk offset: "<<chunkOffset[0]<<std::endl;
        if(chunksToRead.first == attributeDims - 1){
            storyChunkDims[0] = { dims_out[0] - (chunksToRead.first * CHUNK_SIZE) };
            hyperslabMemorySpace = H5Screate_simple(1, storyChunkDims, NULL);
            memSpaceErr = H5Sselect_hyperslab(hyperslabMemorySpace, H5S_SELECT_SET, datasetHyperslabStart, NULL, storyChunkDims, NULL);
            std::cout << "First chunk is last chunk!\n";
        }
        datasetSpaceError = H5Sselect_hyperslab(storyDatasetSpace, H5S_SELECT_SET, chunkOffset, NULL, storyChunkDims, NULL);
        if(datasetSpaceError < 0){
            std::cout<<"error in hyperslab memory space\n";
        }
        hsize_t dims_outt[1];
        status = H5Sget_simple_extent_dims(storyDatasetSpace, dims_outt, NULL);

        std::cout<<dims_outt[0]<<std::endl;
        std::cout << "Reading first chunk!\n";
        status = H5Dread(story, eventType, hyperslabMemorySpace, storyDatasetSpace, H5P_DEFAULT, eventBuffer);
        std::cout << "Read first chunk completed!\n";
        if(status < 0 || datasetSpaceError < 0 || memSpaceErr < 0 || hyperslabMemorySpace < 0){
            if(hyperslabMemorySpace >= 0) H5Sclose(hyperslabMemorySpace);
            free(eventBuffer);
            free(attributeDataBuffer);
            H5Tclose(eventType);
            H5Dclose(story);
            H5Fclose(chronicle);
            std::cout << "error in first chunk!\n";
            return std::make_pair(-1, empVec);
        }
        std::cout << "writing to eventbuffer!\n";
        for(hsize_t i = 0 ; i < storyChunkDims[0]; i++ ){
            if(eventBuffer[i].timeStamp >= range.first && eventBuffer[i].timeStamp <= range.second){
                resultEvents.push_back(eventBuffer[i]);
            }
        }
        std::cout<<"read first chunk and writing completed!"<<std::endl;
        free(eventBuffer);

        /* 
        * Read the intermediate chunks
        */
       
        for(hsize_t i = chunksToRead.first + 1 ; i < chunksToRead.second ; i++){
            std::cout<<"read intermediate chunks and writing!"<<std::endl;
            chunkOffset[0] = {hsize_t(i * CHUNK_SIZE)};
            eventBuffer = (Event*) malloc(CHUNK_SIZE * sizeof(Event));
            datasetSpaceError = H5Sselect_hyperslab(storyDatasetSpace, H5S_SELECT_SET, chunkOffset, NULL, storyChunkDims, NULL);
            status = H5Dread(story, eventType, hyperslabMemorySpace, storyDatasetSpace, H5P_DEFAULT, eventBuffer);

            if(status < 0 || datasetSpaceError < 0 || eventBuffer == NULL){
                if(eventBuffer != NULL) free(eventBuffer);
                free(attributeDataBuffer);
                H5Tclose(eventType);
                H5Sclose(hyperslabMemorySpace);
                H5Dclose(story);
                H5Fclose(chronicle);
                return std::make_pair(-1, empVec);
            }

            // Append data to resultEvents vector
            for(hsize_t index = 0 ; index < storyChunkDims[0]; index++ ){
                resultEvents.push_back(eventBuffer[index]);
            }
            free(eventBuffer);
        }

        /* 
        * Read the last chunk
        */
        if(chunksToRead.first != chunksToRead.second){    // If both the chunks to read are same do not read chunk
            if(chunksToRead.second == attributeDims - 1){
                storyChunkDims[0] = {dims_out[0] - (chunksToRead.second * CHUNK_SIZE) };
                hyperslabMemorySpace = H5Screate_simple(1, storyChunkDims, NULL);
                memSpaceErr = H5Sselect_hyperslab(hyperslabMemorySpace, H5S_SELECT_SET, datasetHyperslabStart, NULL, storyChunkDims, NULL);
            }
            chunkOffset[0] = {hsize_t(chunksToRead.second * CHUNK_SIZE)};
            eventBuffer = (Event*) malloc(CHUNK_SIZE * sizeof(Event));
            datasetSpaceError = H5Sselect_hyperslab(storyDatasetSpace, H5S_SELECT_SET, chunkOffset, NULL, storyChunkDims, NULL);
            status = H5Dread(story, eventType, hyperslabMemorySpace, storyDatasetSpace, H5P_DEFAULT, eventBuffer);

            if(status < 0 || datasetSpaceError < 0 || eventBuffer == NULL ||  memSpaceErr < 0 || hyperslabMemorySpace < 0){
                if(eventBuffer != NULL) free(eventBuffer);
                if(hyperslabMemorySpace >= 0) H5Sclose(hyperslabMemorySpace);
                free(attributeDataBuffer);
                H5Tclose(eventType);
                H5Dclose(story);
                H5Fclose(chronicle);
                return std::make_pair(-1, empVec);
            }

            for(hsize_t i = 0 ; i < storyChunkDims[0]; i++ ){
                if(eventBuffer[i].timeStamp <= range.second){
                    resultEvents.push_back(eventBuffer[i]);
                }
                else{
                    break;
                }
            }
            free(eventBuffer);
        }
    } 
    catch (const std::bad_alloc& e)
    {
        resultEvents.erase(resultEvents.begin(), resultEvents.end());
        if(eventBuffer != NULL) free(eventBuffer);
        if(hyperslabMemorySpace >= 0)   H5Sclose(hyperslabMemorySpace);
        free(attributeDataBuffer);
        H5Tclose(eventType);
        H5Dclose(story);
        H5Fclose(chronicle);
        return std::make_pair(-1, empVec);
    }
    std::cout<<"release resources!"<<std::endl;
    /* 
    * Release resources
    */
    free(attributeDataBuffer);
    H5Sclose(hyperslabMemorySpace);
    H5Tclose(eventType);
    H5Dclose(story);
    H5Fclose(chronicle);

    return std::make_pair(0, resultEvents);
}

// Read story data range i.e Min and Max
std::pair<uint64_t, uint64_t> readDatasetRange(const char* STORY, const char* CHRONICLE){

    std::pair<uint64_t, uint64_t> datasetRange;
    hid_t   chronicle, story, storyDatasetSpace, attributeId, attribute_did;
    hsize_t dims_out[DATASET_RANK];
    herr_t  status;
    uint64_t attribute_value;

    /*
     * Open H5 chronicle and story
     */
    chronicle = H5Fopen(CHRONICLE, H5F_ACC_RDONLY, H5P_DEFAULT);
    story = H5Dopen2(chronicle, STORY, H5P_DEFAULT);

    /*
     * Open and read Min attribute
     */
    attribute_did = H5Aopen(story, ATTRIBUTE_DATASET_MIN, H5P_DEFAULT);
    hid_t attributeDataSpace = H5Aget_space(attribute_did);
    status = H5Aread(attribute_did, H5T_NATIVE_UINT64, &datasetRange.first);

    /*
     * Open and read Max attribute
     */
    attribute_did = H5Aopen(story, ATTRIBUTE_DATASET_MAX, H5P_DEFAULT);
    attributeDataSpace = H5Aget_space(attribute_did);
    status = H5Aread(attribute_did, H5T_NATIVE_UINT64, &datasetRange.second);

    /*
     * Release resources
     */
    H5Aclose(attribute_did);
    H5Sclose(attributeDataSpace);
    H5Dclose(story);
    H5Fclose(chronicle);

    return datasetRange;
}